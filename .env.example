# LLM Configuration
OPENAI_API_KEY=your-openai-key
ANTHROPIC_API_KEY=your-anthropic-key
LLM_TEMPERATURE=0.3

# Local LLM Configuration (Ollama)
# Ollama runs locally and provides various open-source models
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1

# Local LLM Configuration (LM Studio)
# LM Studio provides an OpenAI-compatible API for local models
LMSTUDIO_BASE_URL=http://localhost:1234/v1
LMSTUDIO_MODEL=local-model

# Tool API Keys
TAVILY_API_KEY=your-tavily-key
GITHUB_TOKEN=your-github-token

# Requirements Management - Redmine
# REDMINE_URL=https://redmine.example.com
# REDMINE_API_KEY=your-redmine-api-key

# Requirements Management - Jira
# JIRA_URL=https://company.atlassian.net
# JIRA_USERNAME=email@example.com
# JIRA_API_TOKEN=your-jira-api-token

# LangSmith (optional but recommended for tracing)
LANGCHAIN_API_KEY=your-langsmith-key
LANGCHAIN_PROJECT=solar-flare
LANGCHAIN_TRACING_V2=true

# Vector Store
VECTOR_STORE_PATH=./data/vector_store

# Database (for conversation persistence)
DATABASE_URL=sqlite:///./data/conversations.db
